{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 366,122\n",
      "Trainable params: 366,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 69s 2ms/step - loss: 1.9356 - accuracy: 0.2913 - val_loss: 1.5780 - val_accuracy: 0.4333\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 68s 2ms/step - loss: 1.5782 - accuracy: 0.4274 - val_loss: 1.5927 - val_accuracy: 0.4248\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 69s 2ms/step - loss: 1.4093 - accuracy: 0.4923 - val_loss: 1.3462 - val_accuracy: 0.5151\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 70s 2ms/step - loss: 1.3010 - accuracy: 0.5353 - val_loss: 1.2087 - val_accuracy: 0.5590\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 69s 2ms/step - loss: 1.2088 - accuracy: 0.5689 - val_loss: 1.1524 - val_accuracy: 0.5897\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 68s 2ms/step - loss: 1.1487 - accuracy: 0.5922 - val_loss: 1.1111 - val_accuracy: 0.6030\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 69s 2ms/step - loss: 1.1061 - accuracy: 0.6080 - val_loss: 1.0594 - val_accuracy: 0.6222\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 70s 2ms/step - loss: 1.0625 - accuracy: 0.6245 - val_loss: 1.0847 - val_accuracy: 0.6130\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 70s 2ms/step - loss: 1.0286 - accuracy: 0.6364 - val_loss: 0.9798 - val_accuracy: 0.6483\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 71s 2ms/step - loss: 0.9986 - accuracy: 0.6482 - val_loss: 0.8626 - val_accuracy: 0.6967\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.9647 - accuracy: 0.6606 - val_loss: 0.9734 - val_accuracy: 0.6689\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 74s 2ms/step - loss: 0.9406 - accuracy: 0.6675 - val_loss: 0.8949 - val_accuracy: 0.6875\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 76s 2ms/step - loss: 0.9207 - accuracy: 0.6745 - val_loss: 0.9513 - val_accuracy: 0.6726\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 71s 2ms/step - loss: 0.9021 - accuracy: 0.6811 - val_loss: 0.8644 - val_accuracy: 0.6947\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 71s 2ms/step - loss: 0.8758 - accuracy: 0.6919 - val_loss: 0.8172 - val_accuracy: 0.7161\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 73s 2ms/step - loss: 0.8669 - accuracy: 0.6962 - val_loss: 0.8756 - val_accuracy: 0.7039\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 79s 2ms/step - loss: 0.8551 - accuracy: 0.7010 - val_loss: 1.0962 - val_accuracy: 0.6317\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.8368 - accuracy: 0.7069 - val_loss: 1.2281 - val_accuracy: 0.6016\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 73s 2ms/step - loss: 0.8341 - accuracy: 0.7094 - val_loss: 0.8149 - val_accuracy: 0.7254\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 71s 2ms/step - loss: 0.8178 - accuracy: 0.7138 - val_loss: 0.8364 - val_accuracy: 0.7119\n",
      "10000/10000 [==============================] - 7s 724us/step\n",
      "Test score: 0.8585394239425659\n",
      "Test accuracy: 0.708299994468689\n",
      "Augmenting training set images...\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# CIFAR_10 is a set IMG_CHANNELS = 3 of 60K images 32x32 pixels on Flatten 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "# constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "# load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same')) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same')) \n",
    "model.add(Dropout(0.25)) \n",
    "model.add(Conv2D(64, (3, 3), padding='same')) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Conv2D(64, (3, 3))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same')) \n",
    "model.add(Dropout(0.25)) \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(NB_CLASSES)) \n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, verbose=VERBOSE)\n",
    "\n",
    "# evaluate model\n",
    "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "# augmenting training set images\n",
    "NUM_TO_AUGMENT = 5\n",
    "print(\"Augmenting training set images...\")\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "xtas, ytas = [], []\n",
    "for i in range(X_train.shape[0]):\n",
    "    num_aug = 0\n",
    "    x = X_train[i]  # (3, 32, 32)\n",
    "    x = x.reshape((1,) + x.shape)  # (1, 3, 32, 32)\n",
    "    for x_aug in datagen.flow(x, batch_size=1, save_to_dir='preview', save_prefix='cifar', save_format='jpeg'):\n",
    "        if num_aug >= NUM_TO_AUGMENT:\n",
    "            break\n",
    "        xtas.append(x_aug[0])\n",
    "        num_aug += 1\n",
    "\n",
    "# fit the dataget\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# train with augmented data\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n",
    "                              steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
    "                              epochs=NB_EPOCH, verbose=VERBOSE)\n",
    "\n",
    "# evaluate model with test data\n",
    "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potenial Ethical and Privacy Concerns\n",
    "I think the first one that comes to mind is the idea that we could have an AI out there that is more advanced than this one that is constantly watching the public, Which would scare a lot of people if they didn't know something like this was happening another part of this is concerning the data breaches that could happen around an AI like these especially when they are collecting tons of information both in training data and in actual recordings of a person or group of people.\n",
    "\n",
    "Another part that I think is important to think about is the AIs that use particular artists to train on and then create a new completely AI-generated image but it gets to the point of who owns the trademark of these and how these AI image generation companies could potentially do it the right way in paying the artists for their work and making sure to credit them when posting them online so that way they get a proper reference instead of saying that the AI just came up with it.\n",
    "\n",
    "Arete. (2023, May 11). The implications of AI for authentic, ethical photography. Medium. https://aretestories.medium.com/the-implications-of-ai-for-authentic-ethical-photography-4022d83dad74 \n",
    "Gangarapu, K. R. (2022, January 25). Ethics of facial recognition: Key issues and solutions. Learn Hub. https://learn.g2.com/ethics-of-facial-recognition \n",
    "Noble, B. (2019, December 11). The ethics of AI Image recognition. Cloudera Blog. https://blog.cloudera.com/the-ethics-of-ai-image-recognition/ \n",
    "Roller, J. (2023, December 11). Ethical pros and cons of AI Image Generation. IEEE Computer Society. https://www.computer.org/publications/tech-news/community-voices/ethics-of-ai-image-generation \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
